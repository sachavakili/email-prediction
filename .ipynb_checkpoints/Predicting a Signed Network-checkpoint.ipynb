{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import chdir\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chdir('Library/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] (0%) processed (#1)\n",
      "[train] (1%) processed (#1001)\n",
      "[train] (1%) processed (#2001)\n",
      "[train] (2%) processed (#3001)\n",
      "[train] (3%) processed (#4001)\n",
      "[train] (3%) processed (#5001)\n",
      "[train] (4%) processed (#6001)\n",
      "[train] (5%) processed (#7001)\n",
      "[train] (5%) processed (#8001)\n",
      "[train] (6%) processed (#9001)\n",
      "[train] (7%) processed (#10001)\n",
      "[train] (7%) processed (#11001)\n",
      "[train] (8%) processed (#12001)\n",
      "[train] (9%) processed (#13001)\n",
      "[train] (9%) processed (#14001)\n",
      "[train] (10%) processed (#15001)\n",
      "[train] (11%) processed (#16001)\n",
      "[train] (11%) processed (#17001)\n",
      "[train] (12%) processed (#18001)\n",
      "[train] (13%) processed (#19001)\n",
      "[train] (13%) processed (#20001)\n",
      "[train] (14%) processed (#21001)\n",
      "[train] (15%) processed (#22001)\n",
      "[train] (15%) processed (#23001)\n",
      "[train] (16%) processed (#24001)\n",
      "[train] (17%) processed (#25001)\n",
      "[train] (17%) processed (#26001)\n",
      "[train] (18%) processed (#27001)\n",
      "[train] (19%) processed (#28001)\n",
      "[train] (20%) processed (#29001)\n",
      "[train] (20%) processed (#30001)\n",
      "[train] (21%) processed (#31001)\n",
      "[train] (22%) processed (#32001)\n",
      "[train] (22%) processed (#33001)\n",
      "[train] (23%) processed (#34001)\n",
      "[train] (24%) processed (#35001)\n",
      "[train] (24%) processed (#36001)\n",
      "[train] (25%) processed (#37001)\n",
      "[train] (26%) processed (#38001)\n",
      "[train] (26%) processed (#39001)\n",
      "[train] (27%) processed (#40001)\n",
      "[train] (28%) processed (#41001)\n",
      "[train] (28%) processed (#42001)\n",
      "[train] (29%) processed (#43001)\n",
      "[train] (30%) processed (#44001)\n",
      "[train] (30%) processed (#45001)\n",
      "[train] (31%) processed (#46001)\n",
      "[train] (32%) processed (#47001)\n",
      "[train] (32%) processed (#48001)\n",
      "[train] (33%) processed (#49001)\n",
      "[train] (34%) processed (#50001)\n",
      "[train] (34%) processed (#51001)\n",
      "[train] (35%) processed (#52001)\n",
      "[train] (36%) processed (#53001)\n",
      "[train] (36%) processed (#54001)\n",
      "[train] (37%) processed (#55001)\n",
      "[train] (38%) processed (#56001)\n",
      "[train] (38%) processed (#57001)\n",
      "[train] (39%) processed (#58001)\n",
      "[train] (40%) processed (#59001)\n",
      "[train] (40%) processed (#60001)\n",
      "[train] (41%) processed (#61001)\n",
      "[train] (42%) processed (#62001)\n",
      "[train] (42%) processed (#63001)\n",
      "[train] (43%) processed (#64001)\n",
      "[train] (44%) processed (#65001)\n",
      "[train] (44%) processed (#66001)\n",
      "[train] (45%) processed (#67001)\n",
      "[train] (46%) processed (#68001)\n",
      "[train] (46%) processed (#69001)\n",
      "[train] (47%) processed (#70001)\n",
      "[train] (48%) processed (#71001)\n",
      "[train] (48%) processed (#72001)\n",
      "[train] (49%) processed (#73001)\n",
      "[train] (50%) processed (#74001)\n",
      "[train] (50%) processed (#75001)\n",
      "[train] (51%) processed (#76001)\n",
      "[train] (52%) processed (#77001)\n",
      "[train] (52%) processed (#78001)\n",
      "[train] (53%) processed (#79001)\n",
      "[train] (54%) processed (#80001)\n",
      "[train] (54%) processed (#81001)\n",
      "[train] (55%) processed (#82001)\n",
      "[train] (56%) processed (#83001)\n",
      "[train] (56%) processed (#84001)\n",
      "[train] (57%) processed (#85001)\n",
      "[train] (58%) processed (#86001)\n",
      "[train] (59%) processed (#87001)\n",
      "[train] (59%) processed (#88001)\n",
      "[train] (60%) processed (#89001)\n",
      "[train] (61%) processed (#90001)\n",
      "[train] (61%) processed (#91001)\n",
      "[train] (62%) processed (#92001)\n",
      "[train] (63%) processed (#93001)\n",
      "[train] (63%) processed (#94001)\n",
      "[train] (64%) processed (#95001)\n",
      "[train] (65%) processed (#96001)\n",
      "[train] (65%) processed (#97001)\n",
      "[train] (66%) processed (#98001)\n",
      "[train] (67%) processed (#99001)\n",
      "[train] (67%) processed (#100001)\n",
      "[train] (68%) processed (#101001)\n",
      "[train] (69%) processed (#102001)\n",
      "[train] (69%) processed (#103001)\n",
      "[train] (70%) processed (#104001)\n",
      "[train] (71%) processed (#105001)\n",
      "[train] (71%) processed (#106001)\n",
      "[train] (72%) processed (#107001)\n",
      "[train] (73%) processed (#108001)\n",
      "[train] (73%) processed (#109001)\n",
      "[train] (74%) processed (#110001)\n",
      "[train] (75%) processed (#111001)\n",
      "[train] (75%) processed (#112001)\n",
      "[train] (76%) processed (#113001)\n",
      "[train] (77%) processed (#114001)\n",
      "[train] (77%) processed (#115001)\n",
      "[train] (78%) processed (#116001)\n",
      "[train] (79%) processed (#117001)\n",
      "[train] (79%) processed (#118001)\n",
      "[train] (80%) processed (#119001)\n",
      "[train] (81%) processed (#120001)\n",
      "[train] (81%) processed (#121001)\n",
      "[train] (82%) processed (#122001)\n",
      "[train] (83%) processed (#123001)\n",
      "[train] (83%) processed (#124001)\n",
      "[train] (84%) processed (#125001)\n",
      "[train] (85%) processed (#126001)\n",
      "[train] (85%) processed (#127001)\n",
      "[train] (86%) processed (#128001)\n",
      "[train] (87%) processed (#129001)\n",
      "[train] (87%) processed (#130001)\n",
      "[train] (88%) processed (#131001)\n",
      "[train] (89%) processed (#132001)\n",
      "[train] (89%) processed (#133001)\n",
      "[train] (90%) processed (#134001)\n",
      "[train] (91%) processed (#135001)\n",
      "[train] (91%) processed (#136001)\n",
      "[train] (92%) processed (#137001)\n",
      "[train] (93%) processed (#138001)\n",
      "[train] (93%) processed (#139001)\n",
      "[train] (94%) processed (#140001)\n",
      "[train] (95%) processed (#141001)\n",
      "[train] (95%) processed (#142001)\n",
      "[train] (96%) processed (#143001)\n",
      "[train] (97%) processed (#144001)\n",
      "[train] (98%) processed (#145001)\n",
      "[train] (98%) processed (#146001)\n",
      "[train] (99%) processed (#147001)\n",
      "[train] (100%) processed (#148001)\n",
      "[test] (0%) processed (#1)\n",
      "[test] (2%) processed (#1001)\n",
      "[test] (4%) processed (#2001)\n",
      "[test] (6%) processed (#3001)\n",
      "[test] (8%) processed (#4001)\n",
      "[test] (10%) processed (#5001)\n",
      "[test] (12%) processed (#6001)\n",
      "[test] (14%) processed (#7001)\n",
      "[test] (16%) processed (#8001)\n",
      "[test] (18%) processed (#9001)\n",
      "[test] (20%) processed (#10001)\n",
      "[test] (22%) processed (#11001)\n",
      "[test] (24%) processed (#12001)\n",
      "[test] (26%) processed (#13001)\n",
      "[test] (28%) processed (#14001)\n",
      "[test] (30%) processed (#15001)\n",
      "[test] (32%) processed (#16001)\n",
      "[test] (34%) processed (#17001)\n",
      "[test] (36%) processed (#18001)\n",
      "[test] (38%) processed (#19001)\n",
      "[test] (40%) processed (#20001)\n",
      "[test] (42%) processed (#21001)\n",
      "[test] (44%) processed (#22001)\n",
      "[test] (46%) processed (#23001)\n",
      "[test] (48%) processed (#24001)\n",
      "[test] (50%) processed (#25001)\n",
      "[test] (52%) processed (#26001)\n",
      "[test] (54%) processed (#27001)\n",
      "[test] (56%) processed (#28001)\n",
      "[test] (59%) processed (#29001)\n",
      "[test] (61%) processed (#30001)\n",
      "[test] (63%) processed (#31001)\n",
      "[test] (65%) processed (#32001)\n",
      "[test] (67%) processed (#33001)\n",
      "[test] (69%) processed (#34001)\n",
      "[test] (71%) processed (#35001)\n",
      "[test] (73%) processed (#36001)\n",
      "[test] (75%) processed (#37001)\n",
      "[test] (77%) processed (#38001)\n",
      "[test] (79%) processed (#39001)\n",
      "[test] (81%) processed (#40001)\n",
      "[test] (83%) processed (#41001)\n",
      "[test] (85%) processed (#42001)\n",
      "[test] (87%) processed (#43001)\n",
      "[test] (89%) processed (#44001)\n",
      "[test] (91%) processed (#45001)\n",
      "[test] (93%) processed (#46001)\n",
      "[test] (95%) processed (#47001)\n",
      "[test] (97%) processed (#48001)\n",
      "[test] (99%) processed (#49001)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: svakili\n",
    "\n",
    "Purpose : Research Seminar - Link prediction\n",
    "Baseline Test\n",
    "\n",
    "Notes\n",
    "------\n",
    "colnames of NODE_INFOrmation.csv\n",
    "# (1) SRC source name (string)\n",
    "# (2) TGT target name (string)\n",
    "# (3) VOT vote of the SRC for the TGT (integer)\n",
    "# (4) RES vote of the majority for the TGT (integer)\n",
    "# (5) YEA year of the vote (integer)\n",
    "# (6) DAT date of the vote (string)\n",
    "# (7) TXT text explaining the vote (string)\n",
    "\"\"\"\n",
    "# Python standard\n",
    "import csv\n",
    "# Machine learning libs\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# User scripts\n",
    "from utilis import load_data\n",
    "\n",
    "from features import Year\n",
    "\n",
    "\n",
    "# Limit size of training set (None for no limit)\n",
    "MAX_DATA_SIZE = None\n",
    "\n",
    "\n",
    "#%% Load data\n",
    "\n",
    "# the columns of the data frame below are:\n",
    "# (1) paper unique ID (integer)\n",
    "# (2) publication year (integer)\n",
    "# (3) paper title (string)\n",
    "# (4) authors (strings separated by ,)\n",
    "# (5) name of journal (optional) (string)\n",
    "# (6) abstract (string) - lowercased, free of punctuation except intra-word dashes\n",
    "\n",
    "# paper id to index in NODE_INFO\n",
    "ITRAIN, ITEST, YTRAIN, YTEST, NODE_INFO = load_data(max_data_size=MAX_DATA_SIZE)\n",
    "\n",
    "# Concatenate previous prediction scores to Title/Author/Year features\n",
    "FT = Year(NODE_INFO)\n",
    "XTRAIN = FT.get_features(ITRAIN, 'train')\n",
    "XTEST = FT.get_features(ITEST, 'test')\n",
    "\n",
    "# Reshaping because 1D\n",
    "XTRAIN = XTRAIN.reshape(-1, 1)\n",
    "XTEST = XTEST.reshape(-1, 1)\n",
    "\n",
    "# print 'Fitting Gaussian SVM'\n",
    "# CLASSIFIER = svm.SVC(kernel='rbf', C=100, gamma=10, cache_size=4000, verbose=True)\n",
    "\n",
    "# CLASSIFIER.fit(XTRAIN, YTRAIN)\n",
    "# # Precict on test set\n",
    "# PTEST = CLASSIFIER.predict(XTEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.729790796667\n",
      "F1 0.615790774152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sacha\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Sacha\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "with open('../wikipedia_admin/results/baseline_predictions.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader, None)\n",
    "        PTEST = np.asarray([element[1] for element in reader]) \n",
    "        \n",
    "# Evaluation metrics\n",
    "ACCURACY = metrics.accuracy_score(YTEST, PTEST)\n",
    "F1 = metrics.f1_score(YTEST, PTEST)\n",
    "print 'Accuracy', ACCURACY\n",
    "print 'F1', F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-1' 10196L]\n",
      " ['0' 3198L]\n",
      " ['1' 36175L]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(YTEST, return_counts=True)\n",
    "\n",
    "print np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '49569']]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(PTEST, return_counts=True)\n",
    "\n",
    "print np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
